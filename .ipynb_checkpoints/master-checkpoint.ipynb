{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT & SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "from functools import wraps\n",
    "\n",
    "#Utilities\n",
    "import datetime as dt\n",
    "import holidays\n",
    "import yfinance as yf\n",
    "import itertools\n",
    "\n",
    "#Google sheets -------------------------------------------------------\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "#Kaggle\n",
    "import kaggle\n",
    "\n",
    "#Google API\n",
    "from google.cloud import bigquery\n",
    "#from google.cloud import storage # Imports the Google Cloud storage library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Google Sheets\n",
    "scope = [\"https://spreadsheets.google.com/feeds\",'https://www.googleapis.com/auth/spreadsheets',\"https://www.googleapis.com/auth/drive.file\",\"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"personal-finance-aug30-compute.json\", scope)\n",
    "sheetsclient = gspread.authorize(creds)\n",
    "\n",
    "workbook = sheetsclient.open(\"personal_finance_test\")  # Open the workbook\n",
    "\n",
    "#Set up BigQuery\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"personal-finance-aug30-bigquery.json\"\n",
    "bigquery_client = bigquery.Client() # Instantiates a client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0,
     53,
     71,
     90
    ]
   },
   "outputs": [],
   "source": [
    "def get_closest_date(date):\n",
    "    \"\"\"\n",
    "    ###Get the closest business date:\n",
    "    first ret: date format\n",
    "    second ret: string format\n",
    "    ###\n",
    "    \n",
    "    Args:\n",
    "    date: date to be evaluated on (String)\n",
    "    \n",
    "    Returns:\n",
    "    date: Closest business date (Date)\n",
    "    \"\"\"\n",
    "    x = 0\n",
    "    \n",
    "    if type(date) != str:\n",
    "        date = dt.datetime.strftime(date,\"%Y-%m-%d\")\n",
    "    \n",
    "    def is_business_day(date):\n",
    "        HOLIDAYS_US = holidays.US()\n",
    "\n",
    "        this_day = dt.datetime.strptime(date,\"%Y-%m-%d\")\n",
    "        check = True\n",
    "        if this_day.weekday() in holidays.WEEKEND or this_day in HOLIDAYS_US:\n",
    "            check = False\n",
    "        return check\n",
    "\n",
    "    def next_business_day(date):\n",
    "        ONE_DAY = dt.timedelta(days=1)\n",
    "        HOLIDAYS_US = holidays.US()\n",
    "\n",
    "        next_day = dt.datetime.strptime(date,\"%Y-%m-%d\") + ONE_DAY\n",
    "        while next_day.weekday() in holidays.WEEKEND or next_day in HOLIDAYS_US:\n",
    "            next_day += ONE_DAY\n",
    "        return next_day\n",
    "    \n",
    "    def prior_business_day(date):\n",
    "        ONE_DAY = dt.timedelta(days=1)\n",
    "        HOLIDAYS_US = holidays.US()\n",
    "\n",
    "        prior_day = dt.datetime.strptime(date,\"%Y-%m-%d\") - ONE_DAY\n",
    "        while prior_day.weekday() in holidays.WEEKEND or prior_day in HOLIDAYS_US:\n",
    "            prior_day -= ONE_DAY\n",
    "        return prior_day\n",
    "    \n",
    "    if is_business_day(date) == True:\n",
    "        x = dt.datetime.strptime(date,\"%Y-%m-%d\")\n",
    "    else:\n",
    "        x = prior_business_day(date)\n",
    "    return (x,dt.datetime.strftime(x,\"%Y-%m-%d\"))\n",
    "\n",
    "def running_sum(df,new_col,calc_col):\n",
    "    \"\"\"\n",
    "    Calculating running_sum and store in a new column\n",
    "    \n",
    "    Args:\n",
    "        df: exisiting dataframe (DataFrame)\n",
    "        new_col: a new column to be added (String)\n",
    "        calc_col: a column to be calculated on (String)\"\"\"\n",
    "    \n",
    "    df[new_col] = 0\n",
    "    \n",
    "    for i in enumerate(df[calc_col]):\n",
    "        if i[0] == 0:\n",
    "            df[new_col].iloc[i[0]] = df[calc_col].iloc[i[0]]\n",
    "        else:\n",
    "            df[new_col].iloc[i[0]] = df[new_col].iloc[i[0]-1] + df[calc_col].iloc[i[0]]\n",
    "\n",
    "# fallstockpricesdf['FFSDX'].first_valid_index()\n",
    "def running_log_ret(df,new_col,calc_col):\n",
    "    \"\"\"\n",
    "    Calculating running_sum and store in a new column\n",
    "    \n",
    "    Args:\n",
    "        df: exisiting dataframe (DataFrame)\n",
    "        new_col: a new column to be added (String)\n",
    "        calc_col: a column to be calculated on (String)\"\"\"\n",
    "    \n",
    "    df[new_col] = 0\n",
    "    \n",
    "    for i in enumerate(df[calc_col]):\n",
    "        if i[0] == 0:\n",
    "            df[new_col].iloc[i[0]] = 0\n",
    "        else:\n",
    "            df[new_col].iloc[i[0]] = np.log(df[calc_col].iloc[i[0]]/df[calc_col].iloc[i[0]-1])\n",
    "    \n",
    "    return(df)\n",
    "            \n",
    "def log_ret_with_contribution(df,new_col,calc_col,contributiondf):\n",
    "    \"\"\"\n",
    "    Calculating running_sum and store in a new column\n",
    "    \n",
    "    Args:\n",
    "        df: exisiting dataframe (DataFrame)\n",
    "        new_col: a new column to be added (String)\n",
    "        calc_col: a column to be calculated on (String)\"\"\"\n",
    "    \n",
    "    df[new_col] = 0\n",
    "    \n",
    "    for i in enumerate(df[calc_col]):\n",
    "        if i[0] == 0:\n",
    "            df[new_col].iloc[i[0]] = np.log(df[calc_col].iloc[i[0]]/contributiondf['Amount'].iloc[i[0]])\n",
    "        else:\n",
    "            df[new_col].iloc[i[0]] = np.log(df[calc_col].iloc[i[0]]/(contributiondf['Amount'].iloc[i[0]] + \n",
    "                                                                     df[calc_col].iloc[i[0]-1]))\n",
    "            \n",
    "#GET HISTORICAL STOCK PRICES ----------------------------------------------------------------------------\n",
    "def historical_price(listofstocks,startdate,enddate):\n",
    "    stockprice = {}\n",
    "    for stock in listofstocks:\n",
    "        #get data on specified ticker\n",
    "        tickerData = yf.Ticker(stock)\n",
    "\n",
    "        #get the historical prices for this ticker\n",
    "#         tickerdf = tickerData.history(period='1d', start=startdate, end=enddate+dt.timedelta(days=1))['Close']\n",
    "        tickerdf = tickerData.history(period='1d', start=startdate, end=enddate)['Close']\n",
    "\n",
    "        stockprice[stock] = tickerdf\n",
    "    return stockprice\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "#GET STOCK PRICES AT EVALUATION DATE --------------------------------------------------------------------\n",
    "#for stock in fstocks:\n",
    "#    print(stockprice[stock][dt.datetime.strftime(evaldate,\"%Y-%m-%d\")])\n",
    "\n",
    "\n",
    "def gsheets_update_rows(sheetname,df):\n",
    "    #Format list of list\n",
    "    lst = []\n",
    "    for i in df.itertuples():\n",
    "        lst.append(list(i))\n",
    "\n",
    "    #Update rows\n",
    "    workbook.values_update(\n",
    "        f'{sheetname}!A2',\n",
    "        params={'valueInputOption': 'USER_ENTERED'},\n",
    "        body={'values': lst})\n",
    "    \n",
    "def gsheets_update_names(sheetname,lst):\n",
    "    workbook.values_update(\n",
    "    f'{sheetname}!A1',\n",
    "    params={'valueInputOption': 'USER_ENTERED'},\n",
    "    body={'values': [lst]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT EXTRA SAUCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutual Funds Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutual fund universe from Kaggle Public Data at https://www.kaggle.com/stefanoleone992/mutual-funds-and-etfs\n",
    "mutualfunddf = pd.read_csv('Mutual Funds.csv')\n",
    "mutualfunddf = mutualfunddf.set_index('fund_name') #Set ticker as index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get universe comparison (average, min, max) with indices of category and investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of parameters\n",
    "universelist = [('morningstar_rating','mean'),('fund_family','count')]\n",
    "universedf = pd.DataFrame()\n",
    "for i in enumerate(universelist):\n",
    "    if i[0] == 0:\n",
    "        if i[1][1] == 'mean':\n",
    "            universedf = pd.DataFrame(mutualfunddf[['category','investment',i[1][0]]].groupby(['category','investment'])[i[1][0]].mean())\n",
    "        elif i[1][1] == 'count':\n",
    "            universedf = pd.DataFrame(mutualfunddf[['category','investment',i[1][0]]].groupby(['category','investment'])[i[1][0]].count())\n",
    "    elif i[0] > 0:\n",
    "        if i[1][1] == 'mean':\n",
    "            universedf = universedf.join(pd.DataFrame(mutualfunddf[['category','investment',i[1][0]]].groupby(['category','investment'])[i[1][0]].mean()),how='left')\n",
    "        elif i[1][1] == 'count':\n",
    "            universedf = universedf.join(pd.DataFrame(mutualfunddf[['category','investment',i[1][0]]].groupby(['category','investment'])[i[1][0]].count()),how='left')\n",
    "\n",
    "# pd.DataFrame(mutualfunddf[['category','investment','morningstar_rating']].groupby(['category','investment'])['morningstar_rating'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of parameters\n",
    "universelist = [('morningstar_rating','mean'),('fund_family','count')]\n",
    "universedf = pd.DataFrame()\n",
    "for i in enumerate(universelist):\n",
    "    if i[0] == 0:\n",
    "        if i[1][1] == 'mean':\n",
    "            universedf = pd.DataFrame(mutualfunddf[['category','investment','size',i[1][0]]].groupby(['category','investment','size'])[i[1][0]].mean())\n",
    "        elif i[1][1] == 'count':\n",
    "            universedf = pd.DataFrame(mutualfunddf[['category','investment','size',i[1][0]]].groupby(['category','investment','size'])[i[1][0]].count())\n",
    "    elif i[0] > 0:\n",
    "        if i[1][1] == 'mean':\n",
    "            universedf = universedf.join(pd.DataFrame(mutualfunddf[['category','investment','size',i[1][0]]].groupby(['category','investment','size'])[i[1][0]].mean()),how='left')\n",
    "        elif i[1][1] == 'count':\n",
    "            universedf = universedf.join(pd.DataFrame(mutualfunddf[['category','investment','size',i[1][0]]].groupby(['category','investment','size'])[i[1][0]].count()),how='left')\n",
    "\n",
    "# pd.DataFrame(mutualfunddf[['category','investment','morningstar_rating']].groupby(['category','investment'])['morningstar_rating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PORTFOLIO IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Read history of transactions from Fidelity & Formatting.\n",
    "This only includes data for the funds that have been in the portfolio ONLY. All available investments \n",
    "will be imported later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelitydf = pd.read_excel('history.xlsx',skiprows=5)\n",
    "inceptiondate = fidelitydf['Date'].min()\n",
    "keys = fidelitydf['Investment'].unique().tolist()\n",
    "fstocks = ['FXAIX','FBAKX','MEIKX','OAKMX','JATTX','JGMNX','FBALX','AAGPX','FXAIX']\n",
    "values = iter(fstocks)\n",
    "sdict = {}\n",
    "for i in keys:\n",
    "    sdict[i] = next(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Investment Code using sdict\n",
    "fidelitydf['InvestmentCode'] = fidelitydf['Investment'].map(sdict)\n",
    "\n",
    "#Replace FID 500 INDEX INST with FID 500 INDEX\n",
    "fidelitydf['Investment'] = fidelitydf['Investment'].replace(\"FID 500 INDEX INST\",\"FID 500 INDEX\")\n",
    "\n",
    "#Create lookup keys\n",
    "fidelitydf['Lookup_keys'] = pd.Series(str(val) for val in fidelitydf['Date']) + fidelitydf['InvestmentCode']\n",
    "\n",
    "#Remove duplicates from list\n",
    "fstocks = list(sdict.fromkeys(fstocks))\n",
    "\n",
    "#Write to csv and re-read\n",
    "fidelitydf.to_csv('fidelity.csv',encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET UP UNIVERSAL DATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dates\n",
    "startdate = dt.date.isoformat(fidelitydf['Date'].min())\n",
    "enddate = dt.date.isoformat(fidelitydf['Date'].max())\n",
    "today = dt.date.today()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL FIDELITY INVESTMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fidelitylst = pd.read_csv('fidelity_list.csv',encoding = \"ISO-8859-1\")\n",
    "fidelitylst = fidelitylst.drop(columns=['Unnamed: 6'])\n",
    "\n",
    "lst = []\n",
    "#Currently own investments string\n",
    "for i in fidelitylst['Name/Inception Date']:\n",
    "    lst.append(str(i).strip(\"Investments you currently own√ø\"))\n",
    "fidelitylst['Name/Inception Date'] = lst\n",
    "\n",
    "#ADD investment code\n",
    "lst = []\n",
    "for i in fidelitylst['Name/Inception Date']:\n",
    "    start = i.find('(') + 1\n",
    "    end = i.find(')')\n",
    "    i = i[start:end]\n",
    "    lst.append(i)\n",
    "\n",
    "#Keep only valid code\n",
    "fidelitylst['Code'] = lst\n",
    "fidelitylst = fidelitylst[list(map(lambda x: len(x)<= 5, [*fidelitylst['Code']]))]\n",
    "\n",
    "#ADD Investment Names\n",
    "fidelitylst['Name'] = list(map(lambda x:x.split('(',2)[0].strip(), list(fidelitylst['Name/Inception Date'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [*fidelitylst['Code']]\n",
    "lst.extend(['AAGPX', 'FBALX', 'OAKMX', 'JATTX']) # Add back the inactive funds\n",
    "#Get historical data\n",
    "fstockprices = historical_price(lst,startdate,today)\n",
    "\n",
    "#Convert to dataframe\n",
    "fallstockpricesdf = pd.DataFrame.from_dict(fstockprices)\n",
    "\n",
    "#Convert datetime to date in string format for export\n",
    "fallstockpricesdf['date'] = list(map(lambda x:dt.datetime.strftime(x,'%Y-%m-%d'),[*fallstockpricesdf.index]))\n",
    "fallstockpricesdf = fallstockpricesdf.set_index('date')\n",
    "\n",
    "#Just the ones in the portfolio\n",
    "fstockpricesdf = fallstockpricesdf[fstocks]\n",
    "\n",
    "#Fill NAs\n",
    "exportfallstockpricesdf = fallstockpricesdf.copy().fillna('')\n",
    "# fallstockpricesdf.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## historical_price - Write to google sheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "sheetname = 'historical_price'\n",
    "workbook.values_clear(f'{sheetname}!A2:ZZ1000')\n",
    "\n",
    "lst = [*exportfallstockpricesdf.columns]\n",
    "lst.insert(0,'Date')\n",
    "\n",
    "# Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,exportfallstockpricesdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup - Write to google sheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write ONLY trading dates to gsheets\n",
    "datedf = pd.DataFrame(exportfallstockpricesdf.index).set_index('date')\n",
    "\n",
    "#Write to gsheets\n",
    "sheetname = 'setup'\n",
    "workbook.values_clear(f'{sheetname}!A1:ZZ1000')\n",
    "\n",
    "lst = ['Date']\n",
    "\n",
    "# Update column names\n",
    "gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,datedf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIVERSE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## investment_universe - Get universe data for ALL the investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# universedf.loc[mutualfunddf.loc['ANAIX','category'],mutualfunddf.loc['ANAIX','investment'],mutualfunddf.loc['ANAIX','size']]\n",
    "#Find investment NOT in the universe\n",
    "lst = []\n",
    "for i in [*exportfallstockpricesdf.columns]:\n",
    "    if (i in [*mutualfunddf.index]):\n",
    "        continue\n",
    "    else:\n",
    "        lst.append(i)\n",
    "\n",
    "# pd.DataFrame.from_dict(fstockprices)\n",
    "testdf = pd.DataFrame.from_dict({'category':['Target-Date 2060+'],'investment':['Blend'],'size':['Large']}).transpose()\n",
    "testdf.columns = ['FFSDX']\n",
    "testdf = testdf.transpose()\n",
    "\n",
    "mutualfunddf = pd.concat([mutualfunddf,testdf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform before exporting to gsheets\n",
    "lst = []\n",
    "for i in [*exportfallstockpricesdf.columns]:\n",
    "    lst.append(mutualfunddf.loc[i,['category','investment','size']])\n",
    "    \n",
    "universeportdf = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "sheetname = 'investment_universe'\n",
    "workbook.values_clear(f'{sheetname}!A1:ZZ1000')\n",
    "\n",
    "lst = [*universeportdf.columns]\n",
    "lst.insert(0,'Fund')\n",
    "\n",
    "# Update column names\n",
    "gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,universeportdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write revised mutual fund df to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*NOTE This step only needs to be done once to set up the dataset for the project, the universe data is updated\n",
    "every 3 months or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Format to export to BigQuery\n",
    "mutualfundexportdf = mutualfunddf.copy()\n",
    "mutualfundexportdf['fund'] = [*mutualfundexportdf.index] #Adding back funds\n",
    "\n",
    "#Write to BigQuery\n",
    "mutualfundexportdf.to_gbq('mutual_fund_universe.universe',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query from the mutual fund data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE table for peer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(f\"\"\"\n",
    "    DROP TABLE IF EXISTS `personal-finance-aug30.mutual_fund_universe.peer_count`;\n",
    "    CREATE TABLE `personal-finance-aug30.mutual_fund_universe.peer_count` AS\n",
    "    SELECT DISTINCT fund,category,investment,size,count(*) OVER(PARTITION BY category, investment, size) as count\n",
    "    FROM `personal-finance-aug30.mutual_fund_universe.universe`\n",
    "\"\"\")\n",
    "results = query_job.result()  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and percentile for alpha, beta, sharpe, treynor, returns & standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['fund_alpha_10years','fund_alpha_3years','fund_alpha_5years','fund_beta_10years','fund_beta_3years',\n",
    "       'fund_beta_5years','fund_return_10years','fund_return_3years','fund_return_5years']\n",
    "splitnamelst = ['fund_alpha_10years','fund_alpha_3years','fund_alpha_5years','fund_beta_10years','fund_beta_3years',\n",
    "       'fund_beta_5years','fund_return_10years','fund_return_3years','fund_return_5years']\n",
    "       \n",
    "customname = ['fund_sharpe_ratio_10years','fund_sharpe_ratio_3years','fund_sharpe_ratio_5years',\n",
    "'fund_treynor_ratio_10years','fund_treynor_ratio_3years','fund_treynor_ratio_5years',\n",
    "'fund_standard_deviation_10years','fund_standard_deviation_3years','fund_standard_deviation_5years']\n",
    "\n",
    "lst.extend(customname)\n",
    "splitnamelst.extend(list(map(lambda x:x.split('_')[0]+'_'+x.split('_')[1]+x.split('_')[2]+'_'+x.split('_')[3],customname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through ALL the specified in the list\n",
    "for parameter in list(zip(lst,splitnamelst)):\n",
    "    query_job = bigquery_client.query(\n",
    "        f\"\"\"\n",
    "        DROP TABLE IF EXISTS `personal-finance-aug30.mutual_fund_universe.merge_{parameter[0]}`;\n",
    "        CREATE TABLE `personal-finance-aug30.mutual_fund_universe.merge_{parameter[0]}` AS\n",
    "        SELECT fund, percent_rank() OVER(PARTITION BY category, investment, size ORDER BY {parameter[0]}) as percentile, {parameter[0]} as value,\n",
    "        '{parameter[1]}' as parameter,\n",
    "        FROM `personal-finance-aug30.mutual_fund_universe.universe` \n",
    "        WHERE {parameter[0]} is not null\"\"\")\n",
    "    results = query_job.result()  # Waits for job to complete.\n",
    "\n",
    "#Merge\n",
    "query_job = bigquery_client.query(\n",
    "    f\"\"\"\n",
    "    -- DROP TABLE IF EXISTS `personal-finance-aug30.mutual_fund_universe.percentile_universe`;\n",
    "    -- CREATE TABLE `personal-finance-aug30.mutual_fund_universe.percentile_universe` AS\n",
    "    DELETE FROM `personal-finance-aug30.mutual_fund_universe.percentile_universe` WHERE True;\n",
    "    INSERT INTO `personal-finance-aug30.mutual_fund_universe.percentile_universe`\n",
    "    SELECT * FROM `personal-finance-aug30.mutual_fund_universe.merge_*`\n",
    "    \"\"\")\n",
    "results = query_job.result()  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and percentile for yearly return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['fund_return_2010','fund_return_2011','fund_return_2012','fund_return_2013','fund_return_2014',\n",
    "       'fund_return_2015','fund_return_2016','fund_return_2017','fund_return_2018']\n",
    "# 'morningstar_return_rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through ALL the specified in the list\n",
    "for parameter in lst:\n",
    "    query_job = bigquery_client.query(\n",
    "        f\"\"\"\n",
    "        DROP TABLE IF EXISTS `personal-finance-aug30.mutual_fund_universe.return_{parameter}`;\n",
    "        CREATE TABLE `personal-finance-aug30.mutual_fund_universe.return_{parameter}` AS\n",
    "        SELECT fund, percent_rank() OVER(PARTITION BY category, investment, size ORDER BY {parameter}) as percentile, {parameter} as value,\n",
    "        '{parameter}' as parameter,\n",
    "        FROM `personal-finance-aug30.mutual_fund_universe.universe` \n",
    "        WHERE {parameter} is not null\"\"\")\n",
    "    results = query_job.result()  # Waits for job to complete.\n",
    "    \n",
    "#Merge\n",
    "query_job = bigquery_client.query(\n",
    "    f\"\"\"\n",
    "    DROP TABLE IF EXISTS `personal-finance-aug30.mutual_fund_universe.return_universe`;\n",
    "    CREATE TABLE `personal-finance-aug30.mutual_fund_universe.return_universe` AS\n",
    "    -- DELETE FROM `personal-finance-aug30.mutual_fund_universe.return_universe` WHERE True;\n",
    "    -- INSERT INTO `personal-finance-aug30.mutual_fund_universe.return_universe`\n",
    "    SELECT * FROM `personal-finance-aug30.mutual_fund_universe.return_*`\n",
    "    \"\"\")\n",
    "results = query_job.result()  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BENCHMARKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import mapping from gsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = sheetsclient.open(\"personal_finance_test\").sheet1  # Open the spreadhseet master\n",
    "\n",
    "#Loop to create dictionary for mapping investments\n",
    "data = pd.DataFrame(sheet.get_all_records())  # Get a list of all records\n",
    "\n",
    "keys = data.Fund\n",
    "values = iter(data.Ticker)\n",
    "benchmarkdict = {}\n",
    "for i in keys:\n",
    "    benchmarkdict[i] = next(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark_returns - Get price/returns for benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all unique benchmarks\n",
    "benchmarkslst = [*pd.Series([*benchmarkdict.values()]).unique()]\n",
    "\n",
    "#Get prices\n",
    "benchmarkprices = historical_price(benchmarkslst,startdate,today)\n",
    "\n",
    "#Get returns\n",
    "for key in benchmarkprices.keys():\n",
    "    benchmarkprices[key] = running_log_ret(pd.DataFrame(benchmarkprices[key]),'LogRet','Close').drop(columns=['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datedf = pd.DataFrame(exportfallstockpricesdf.index).set_index('date')\n",
    "\n",
    "benchmarkretdf = pd.DataFrame()\n",
    "for i in enumerate([*benchmarkprices.keys()]):\n",
    "    if i[0] == 0:\n",
    "        benchmarkretdf = benchmarkprices[i[1]].join(datedf,how='left')\n",
    "        benchmarkretdf.columns = [i[1]]\n",
    "    else:\n",
    "        benchmarkretdf[i[1]] = benchmarkprices[i[1]].join(datedf,how='left').iloc[:,0]\n",
    "        \n",
    "benchmarkretdf = benchmarkretdf.ffill() #Forward fill\n",
    "\n",
    "#Convert datetime to date in string format for export\n",
    "benchmarkretdf['date'] = list(map(lambda x:dt.datetime.strftime(x,'%Y-%m-%d'),[*benchmarkretdf.index]))\n",
    "benchmarkretdf = benchmarkretdf.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "sheetname = 'benchmark_returns'\n",
    "workbook.values_clear(f'{sheetname}!A2:ZZ1000')\n",
    "\n",
    "lst = [*benchmarkretdf.columns]\n",
    "lst.insert(0,'Date')\n",
    "\n",
    "# Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,benchmarkretdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all the exchanges that happened\n",
    "exchangedf = fidelitydf[fidelitydf['Transaction Type']=='Exchanges']\n",
    "\n",
    "#Get absolute exchange value & classify True/False for excahnge\n",
    "exchangedf['Abs_Amount'] = abs(exchangedf['Amount'])\n",
    "exchangedf['Exchanged'] = exchangedf['Amount'] < 0 #classify\n",
    "exchangedf = exchangedf.sort_values('Abs_Amount')\n",
    "\n",
    "#Adding pairs\n",
    "lst1 = list(itertools.chain.from_iterable(itertools.repeat(x, 2) for x in range(0,int(len(exchangedf)/2))))\n",
    "exchangedf['Switch_Pair'] = lst1\n",
    "\n",
    "#Convert datetime to date in string format for export\n",
    "exchangedf['date'] = list(map(lambda x:str(dt.datetime.strftime(x,'%Y-%m-%d')),list(exchangedf['Date'])))\n",
    "exchangedf = exchangedf.drop(columns=['Date'])\n",
    "# exchangedf= exchangedf.set_index('date')\n",
    "exchangedf['date'] = exchangedf['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "workbook.values_clear('exchanges!A2:ZZ1000')\n",
    "\n",
    "lst = []\n",
    "for i in exchangedf.itertuples():\n",
    "    lst.append(list(i))\n",
    "    \n",
    "#Update rows\n",
    "workbook.values_update(\n",
    "    'exchanges!A2',\n",
    "    params={\n",
    "        'valueInputOption': 'USER_ENTERED'\n",
    "    },\n",
    "    body={\n",
    "        'values': lst\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOLDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnlist = fstocks\n",
    "columnlist.insert(0,'Date')\n",
    "columnlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct HOLDINGS dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all dates that all events taken place\n",
    "datelist = [*fidelitydf['Date'].unique()]\n",
    "datelist.reverse()\n",
    "\n",
    "#Holdingsdf creation\n",
    "holdingsdf = pd.DataFrame(columns=columnlist)\n",
    "holdingsdf['date'] = datelist\n",
    "holdingsdf = holdingsdf.set_index('date')\n",
    "\n",
    "#Initial investments\n",
    "# fidelitydf['Transaction Type'].unique()\n",
    "\n",
    "for date in enumerate(datelist):\n",
    "    #INITIATE\n",
    "    if date[0] == 0:\n",
    "        df = fidelitydf[fidelitydf['Date']==date[1]]\n",
    "        #2 is type 4 is shares, 5 is fund\n",
    "        for i in df.iterrows():\n",
    "            if i[1][2].lower() == 'contribution':\n",
    "                holdingsdf.loc[date[1],i[1][5]] = i[1][4]\n",
    "        holdingsdf.loc[date[1],:] = holdingsdf.loc[date[1],:].fillna(0) #fill all with zeros\n",
    "    else:\n",
    "        df = fidelitydf[fidelitydf['Date']==date[1]]\n",
    "        sumdf = pd.DataFrame(df.groupby('InvestmentCode')['Shares/Unit'].sum())\n",
    "        for i in sumdf.iterrows():\n",
    "            holdingsdf.loc[date[1],i[0]] = float(round(holdingsdf[i[0]][date[0]-1] + i[1],3))\n",
    "\n",
    "        for i in enumerate(holdingsdf.loc[date[1],:]):\n",
    "            if math.isnan(i[1]):\n",
    "                holdingsdf.iloc[:,i[0]][date[0]] = holdingsdf.iloc[:,i[0]][date[0]-1]\n",
    "                \n",
    "holdingsdf = holdingsdf.drop(columns=['Date'])\n",
    "fstocks.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct PORTFOLIO dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill out missing dates\n",
    "portfoliodf = holdingsdf.join(fstockpricesdf,how='right',lsuffix='_share', rsuffix='_price')\n",
    "portfoliodf.ffill(axis = 0,inplace=True)\n",
    "portfoliodf.isna().sum()\n",
    "\n",
    "#Create date dataframe\n",
    "datedf = pd.DataFrame(fstockpricesdf.index)\n",
    "datedf = datedf.set_index('date')\n",
    "\n",
    "#Add value\n",
    "for fund in fstocks:\n",
    "    portfoliodf[fund+'_value'] = portfoliodf[fund+'_share']*portfoliodf[fund+'_price']\n",
    "    \n",
    "#Add total portfolio value:\n",
    "portfoliodf['Amount'] = portfoliodf[[c for c in portfoliodf if c.endswith('value')]].sum(axis=1)\n",
    "\n",
    "#Add log ret for each of the investment:\n",
    "for fund in fstocks:\n",
    "    running_log_ret(portfoliodf,fund+'_ret',fund+'_price')\n",
    "\n",
    "#Add pct composition of the portfolio:\n",
    "for fund in fstocks:\n",
    "    portfoliodf[fund+'_pct'] = portfoliodf[fund+'_value']/portfoliodf['Amount']\n",
    "\n",
    "#Add weighted log ret for each of the investment:\n",
    "for fund in fstocks:\n",
    "    portfoliodf[fund+'_pctport'] = portfoliodf[fund+'_pct']*portfoliodf[fund+'_ret']  \n",
    "    \n",
    "#Add total portfolio value:\n",
    "portfoliodf['LogRet'] = portfoliodf[[c for c in portfoliodf if c.endswith('_pctport')]].sum(axis=1)\n",
    "\n",
    "#Subset to take care of contributions and dividends (reinvested)\n",
    "contributionsdf = pd.DataFrame(fidelitydf[(fidelitydf['Transaction Type']=='CONTRIBUTION')|(fidelitydf['Transaction Type']=='DIVIDEND')].groupby('Date')['Amount'].sum())\n",
    "contributionsdf['Date'] = list(map(lambda x:str(dt.datetime.strftime(x,'%Y-%m-%d')),list(contributionsdf.index)))\n",
    "contributionsdf = contributionsdf.set_index('Date')\n",
    "\n",
    "#Join with datedf to fill in blanks\n",
    "contributionsdf = contributionsdf.join(datedf, how='right').fillna(0)\n",
    "#Add total contributions\n",
    "running_sum(contributionsdf, 'Total Contribution', 'Amount')\n",
    "\n",
    "#Populated log ret for the portfolio\n",
    "# log_ret_with_contribution(portfoliodf,'LogRet','Amount',contributionsdf)\n",
    "\n",
    "#Convert datetime to date in string format for export\n",
    "portfoliodf['Date'] = list(map(lambda x:str(dt.datetime.strftime(x,'%Y-%m-%d')),list(portfoliodf.index)))\n",
    "portfoliodf['Date'] = portfoliodf['Date'].astype(str)\n",
    "portfoliodf = portfoliodf.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfoliodf[['LogRet']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write results to gsheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### portfolio_holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset\n",
    "sharedf = portfoliodf[[c for c in portfoliodf if c.endswith('share')]]\n",
    "\n",
    "#Write to gsheets\n",
    "sheetname = 'portfolio_holdings'\n",
    "workbook.values_clear(f'{sheetname}!A2:ZZ1000')\n",
    "lst = [*sharedf.columns]\n",
    "lst.insert(0,'date')\n",
    "lst = list(map(lambda x:x.split('_',1)[0], lst)) #strip the suffix\n",
    "\n",
    "#Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,sharedf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### portfolio_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset\n",
    "pctdf = portfoliodf[[c for c in portfoliodf if c.endswith('_pct')]]\n",
    "\n",
    "#Write to gsheets\n",
    "sheetname = 'portfolio_pct'\n",
    "workbook.values_clear(f'{sheetname}!A2:ZZ1000')\n",
    "lst = [*pctdf.columns]\n",
    "lst.insert(0,'date')\n",
    "lst = list(map(lambda x:x.split('_',1)[0], lst)) #strip the suffix\n",
    "\n",
    "#Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,pctdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### investment_value - Current share values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharevaldf = pd.DataFrame(portfoliodf[[c for c in portfoliodf if c.endswith('value')]].iloc[-1,])\n",
    "sharevaldf = sharevaldf.set_index(pd.Index(list(map(lambda x:x.split('_',1)[0], [*sharevaldf.index])))) #strip suffix and set as index\n",
    "\n",
    "#Write to gsheets\n",
    "sheetname = 'investment_value'\n",
    "workbook.values_clear(f'{sheetname}!A2:ZZ1000')\n",
    "\n",
    "lst = ['Fund','investment_value']\n",
    "\n",
    "#Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,sharevaldf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA: Write active, inactive, available investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip the _share from the columns\n",
    "sharedf.columns = list(map(lambda x:x.split('_share',1)[0],[*sharedf.columns]))\n",
    "sharedf1 = pd.DataFrame(sharedf.iloc[-1,]).copy()\n",
    "sharedf1['Code'] = [*sharedf1.index]\n",
    "sharedf1 = sharedf1.set_index('Code')\n",
    "sharedf1.columns = ['Value']\n",
    "\n",
    "alldf = pd.DataFrame(fidelitylst['Code']).set_index('Code')\n",
    "sharedf1 = pd.concat([sharedf1,alldf])\n",
    "sharedf1['Code'] = [*sharedf1.index]\n",
    "sharedf1 = sharedf1.drop_duplicates(subset=['Code'],keep='first')\n",
    "\n",
    "#Update the status column\n",
    "lst = []\n",
    "for i in sharedf1.Value:\n",
    "    if i > 0:\n",
    "        lst.append('Active')\n",
    "    elif i == 0:\n",
    "        lst.append('Inactive')\n",
    "    else:\n",
    "        lst.append('Available')\n",
    "sharedf1['Status'] = lst\n",
    "\n",
    "sharedf1 = sharedf1.drop(columns=['Value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YAHOO FINANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the fund info using yfinance\n",
    "lst = []\n",
    "parameterlst = []\n",
    "for fund in [*sharedf1.index]:\n",
    "    yfund = yf.Ticker(fund)\n",
    "\n",
    "    #get parameter info dictionary\n",
    "    parameterlst.extend(yfund.info)\n",
    "    \n",
    "    #get stock info dictionary - list of dictionary\n",
    "    lst.append(yfund.info)\n",
    "\n",
    "#Transform to dictionary and dataframe\n",
    "fundinfodict = dict(zip([*sharedf1.index],lst))\n",
    "fundinfodf = pd.DataFrame(fundinfodict)\n",
    "\n",
    "# #Format for exporting to gsheets\n",
    "# formattedfundinfodf = pd.DataFrame()\n",
    "# testdf = pd.DataFrame()\n",
    "# for col in [*fundinfodf.columns]:\n",
    "#     testdf = pd.DataFrame(fundinfodf[col])\n",
    "#     testdf['Fund'] = col\n",
    "#     testdf.columns = ['Value','Fund']\n",
    "#     formattedfundinfodf = pd.concat([formattedfundinfodf, testdf])\n",
    "\n",
    "# # Remove companyOfficers causing an empty list being written\n",
    "# formattedfundinfodf = formattedfundinfodf.drop(['companyOfficers'])\n",
    "\n",
    "# Remove companyOfficers causing an empty list being written\n",
    "fundinfodf = fundinfodf.drop(['companyOfficers'])\n",
    "keep = ('annualHoldingsTurnover','annualReportExpenseRatio','beta3Year','shortName','morningStarRiskRating',\n",
    "            'morningStarOverallRating','quoteType','yield','ytdReturn')\n",
    "fundinfodf = fundinfodf.loc[keep,].transpose() #subset & transpose\n",
    "sharedf1 = sharedf1.join(fundinfodf,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "sheetname = 'investment_info'\n",
    "workbook.values_clear(f'{sheetname}!A2:L1000')\n",
    "\n",
    "lst = [*sharedf1.columns]\n",
    "lst.insert(0,'Fund')\n",
    "#Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,sharedf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Write to gsheets\n",
    "# sheetname = 'investment_status'\n",
    "# workbook.values_clear(f'{sheetname}!A2:C1000')\n",
    "\n",
    "# # lst = [*sharedf1.columns]\n",
    "# # lst.insert(0,'Fund')\n",
    "\n",
    "# # #Update column names\n",
    "# # gsheets_update_names(sheetname,lst)\n",
    "\n",
    "# #Update rows\n",
    "# gsheets_update_rows(sheetname,sharedf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## portfolio_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get each investment contributions\n",
    "fidelitycontdf = fidelitydf[(fidelitydf['Transaction Type']=='CONTRIBUTION')|(fidelitydf['Transaction Type']=='DIVIDEND')]\n",
    "df = pd.DataFrame(fidelitycontdf[fidelitycontdf['InvestmentCode'] == 'AAGPX'].groupby('Date')['Amount'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customlst = [*fidelitycontdf['InvestmentCode'].unique()]\n",
    "df = pd.DataFrame()\n",
    "testdf = pd.DataFrame()\n",
    "for i in enumerate(customlst):\n",
    "    if i[0] == 0:\n",
    "        df = pd.DataFrame(fidelitydf[fidelitydf['InvestmentCode'] == i[1]].groupby('Date')['Amount'].sum())\n",
    "        df.columns = [i[1]]\n",
    "        df = df.join(datedf,how='right')\n",
    "        df = df.fillna(0)\n",
    "        running_sum(df,i[1]+'_Contribution',i[1])\n",
    "        df = df.ffill()\n",
    "    else:\n",
    "        testdf = pd.DataFrame(fidelitydf[fidelitydf['InvestmentCode'] == i[1]].groupby('Date')['Amount'].sum())\n",
    "        testdf.columns = [i[1]]\n",
    "        testdf = testdf.join(datedf,how='right')\n",
    "        testdf = testdf.fillna(0)\n",
    "        running_sum(testdf,i[1]+'_Contribution',i[1])\n",
    "        testdf = testdf.ffill()\n",
    "        df = df.join(testdf,how='left')\n",
    "        \n",
    "#Join with the portfolio contributions\n",
    "contributionsdf = contributionsdf.join(df,how='left')\n",
    "\n",
    "#Convert datetime to date in string format for export\n",
    "contributionsdf['Date'] = list(map(lambda x:str(dt.datetime.strftime(x,'%Y-%m-%d')),list(contributionsdf.index)))\n",
    "contributionsdf['Date'] = contributionsdf['Date'].astype(str)\n",
    "contributionsdf = contributionsdf.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "sheetname = 'portfolio_contributions'\n",
    "workbook.values_clear(f'{sheetname}!A1:ZZ1000')\n",
    "\n",
    "lst = [*contributionsdf.columns]\n",
    "lst.insert(0,'Date')\n",
    "#Update column names\n",
    "gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,contributionsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## portfolio_returns - Portfolio vs benchmarks (blended benchmark calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get portfolio weights\n",
    "weightdf = portfoliodf[[c for c in portfoliodf if c.endswith('pct')]]\n",
    "\n",
    "#Strip suffix to new column names\n",
    "weightdf.columns = list(map(lambda x:x.split('_',1)[0], [*weightdf.columns])) #strip the suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contruct blendedbenchmarkdf\n",
    "lst = []\n",
    "for fund in weightdf.columns:\n",
    "    lst.append([*benchmarkprices[benchmarkdict[fund]]['LogRet']])\n",
    "\n",
    "blendedbenchmarkdf = pd.DataFrame(lst).transpose()\n",
    "blendedbenchmarkdf.columns = [*weightdf.columns]\n",
    "\n",
    "#Element-wise multiply and sum across\n",
    "blendedbenchmarkdf = pd.DataFrame(weightdf.values*blendedbenchmarkdf.values, columns=weightdf.columns, index=weightdf.index)\n",
    "blendedbenchmarkdf['BenchmarkLogRet'] = blendedbenchmarkdf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not in portfolio\n",
    "notinportfoliodf = fallstockpricesdf[[c for c in fallstockpricesdf if c not in fstocks]].copy()\n",
    "notinportfoliodf.columns = list(map(lambda x:x+'_price',[*notinportfoliodf.columns])) #add price suffix\n",
    "\n",
    "#Add log ret for each of the investment:\n",
    "for fund in [*notinportfoliodf.columns]:\n",
    "    running_log_ret(notinportfoliodf,fund.strip('_price')+'_ret',fund)\n",
    "\n",
    "notinportfoliodf = notinportfoliodf.fillna(\"\")\n",
    "notinportfoliodf = notinportfoliodf[[c for c in notinportfoliodf if c.endswith('ret')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset\n",
    "lst = ['LogRet','Amount']\n",
    "lst.extend([c for c in portfoliodf if c.endswith('ret')])\n",
    "returnsdf = portfoliodf[lst]\n",
    "returnsdf = returnsdf.join(pd.DataFrame(blendedbenchmarkdf['BenchmarkLogRet']),how='left')\n",
    "\n",
    "#Join with the ones NOT in portfolio\n",
    "returnsdf = returnsdf.join(notinportfoliodf,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to gsheets\n",
    "sheetname = 'portfolio_returns'\n",
    "workbook.values_clear(f'{sheetname}!A2:ZZ1000')\n",
    "\n",
    "lst = [*returnsdf.columns]\n",
    "lst.insert(0,'Date')\n",
    "lst = list(map(lambda x:x.split('_',1)[0], lst)) #strip the suffix\n",
    "\n",
    "#Update column names\n",
    "# gsheets_update_names(sheetname,lst)\n",
    "\n",
    "#Update rows\n",
    "gsheets_update_rows(sheetname,returnsdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
